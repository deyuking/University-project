{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>round</th>\n",
       "      <th>weather_warm</th>\n",
       "      <th>weather_cold</th>\n",
       "      <th>weather_dry</th>\n",
       "      <th>weather_wet</th>\n",
       "      <th>weather_cloudy</th>\n",
       "      <th>driver</th>\n",
       "      <th>grid</th>\n",
       "      <th>podium</th>\n",
       "      <th>...</th>\n",
       "      <th>constructor_minardi</th>\n",
       "      <th>constructor_prost</th>\n",
       "      <th>constructor_red_bull</th>\n",
       "      <th>constructor_renault</th>\n",
       "      <th>constructor_sauber</th>\n",
       "      <th>constructor_team_lotus</th>\n",
       "      <th>constructor_toro_rosso</th>\n",
       "      <th>constructor_toyota</th>\n",
       "      <th>constructor_tyrrell</th>\n",
       "      <th>constructor_williams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>keke_rosberg</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>prost</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tambay</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>piquet</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>warwick</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  round  weather_warm  weather_cold  weather_dry  weather_wet  \\\n",
       "0    1983      1         False         False         True        False   \n",
       "1    1983      1         False         False         True        False   \n",
       "2    1983      1         False         False         True        False   \n",
       "3    1983      1         False         False         True        False   \n",
       "4    1983      1         False         False         True        False   \n",
       "\n",
       "   weather_cloudy        driver  grid  podium  ...  constructor_minardi  \\\n",
       "0           False  keke_rosberg     1      15  ...                    0   \n",
       "1           False         prost     2       6  ...                    0   \n",
       "2           False        tambay     3       4  ...                    0   \n",
       "3           False        piquet     4       1  ...                    0   \n",
       "4           False       warwick     5       7  ...                    0   \n",
       "\n",
       "   constructor_prost  constructor_red_bull  constructor_renault  \\\n",
       "0                  0                     0                    0   \n",
       "1                  0                     0                    1   \n",
       "2                  0                     0                    0   \n",
       "3                  0                     0                    0   \n",
       "4                  0                     0                    0   \n",
       "\n",
       "   constructor_sauber  constructor_team_lotus  constructor_toro_rosso  \\\n",
       "0                   0                       0                       0   \n",
       "1                   0                       0                       0   \n",
       "2                   0                       0                       0   \n",
       "3                   0                       0                       0   \n",
       "4                   0                       0                       0   \n",
       "\n",
       "   constructor_toyota  constructor_tyrrell  constructor_williams  \n",
       "0                   0                    0                     1  \n",
       "1                   0                    0                     0  \n",
       "2                   0                    0                     0  \n",
       "3                   0                    0                     0  \n",
       "4                   0                    0                     0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "df.podium = df.podium.map(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "train = df[df.season <2019]\n",
    "X_train = train.drop(['driver', 'podium'], axis = 1)\n",
    "y_train = train.podium\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom function for the score classification model, the driver with the highest probability of winning will be mapped as the winner\n",
    "def score_classification(model):\n",
    "    score = 0\n",
    "    for circuit in df[df.season == 2019]['round'].unique():\n",
    "\n",
    "        test = df[(df.season == 2019) & (df['round'] == circuit)]\n",
    "        X_test = test.drop(['driver', 'podium'], axis = 1)\n",
    "        y_test = test.podium\n",
    "\n",
    "        #scaling\n",
    "        X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "\n",
    "        # make predictions\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['proba_0', 'proba_1'])\n",
    "        prediction_df['actual'] = y_test.reset_index(drop = True)\n",
    "        prediction_df.sort_values('proba_1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)\n",
    "        prediction_df['predicted'] = prediction_df.index\n",
    "        prediction_df['predicted'] = prediction_df.predicted.map(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "        score += precision_score(prediction_df.actual, prediction_df.predicted)\n",
    "\n",
    "    model_score = score / df[df.season == 2019]['round'].unique().max()\n",
    "    return (model_score, prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_dict ={'model':[],\n",
    "                  'params': [],\n",
    "                  'score': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "params={'penalty': ['l1', 'l2'],\n",
    "        'solver': ['saga', 'liblinear'],\n",
    "        'C': np.logspace(-3,1,20)}\n",
    "\n",
    "for penalty in params['penalty']:\n",
    "    for solver in params['solver']:\n",
    "        for c in params['C']:\n",
    "            model_params = (penalty, solver, c)\n",
    "            model = LogisticRegression(penalty = penalty, solver = solver, C = c, max_iter = 10000)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            model_score = score_classification(model)\n",
    "        \n",
    "            comparison_dict['model'].append('logistic_regression')\n",
    "            comparison_dict['params'].append(model_params)\n",
    "            comparison_dict['score'].append(model_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "params={'criterion': ['gini', 'entropy'],\n",
    "        'max_features': [0.8, 'auto', None],\n",
    "        'max_depth': list(np.linspace(5, 55, 26)) + [None]}\n",
    "\n",
    "for criterion in params['criterion']:\n",
    "    for max_features in params['max_features']:\n",
    "        for max_depth in params['max_depth']:\n",
    "            model_params = (criterion, max_features, max_depth)\n",
    "            model = RandomForestClassifier(criterion = criterion, max_features = max_features, max_depth = max_depth)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            model_score = score_classification(model)\n",
    "            \n",
    "            comparison_dict['model'].append('random_forest_classifier')\n",
    "            comparison_dict['params'].append(model_params)\n",
    "            comparison_dict['score'].append(model_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "\n",
    "#Please note that the NN classifier takes around 4+ hours to run due to the grid search for the hyperparameter.\n",
    "#The best hyperparameters can be found in the last table in the notebook.\n",
    "#If you wish to re-run the code please use those.\n",
    "\n",
    "params={'hidden_layer_sizes': [(80,20,40,5), (75,25,50,10)], \n",
    "        'activation': ['identity', 'logistic', 'tanh', 'relu'], \n",
    "        'solver': ['lbfgs', 'sgd', 'adam', 'logistic'], \n",
    "        'alpha': np.logspace(-4,2,20)} \n",
    "\n",
    "\n",
    "for hidden_layer_sizes in params['hidden_layer_sizes']:\n",
    "    for activation in params['activation']:\n",
    "        for solver in params['solver']:\n",
    "            for alpha in params['alpha']:\n",
    "                model_params = (hidden_layer_sizes, activation, solver, alpha )\n",
    "                model = MLPClassifier(hidden_layer_sizes = hidden_layer_sizes,\n",
    "                                      activation = activation, solver = solver, alpha = alpha, random_state = 1)\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                model_score = score_classification(model)\n",
    "\n",
    "                comparison_dict['model'].append('neural_network_classifier')\n",
    "                comparison_dict['params'].append(model_params)\n",
    "                comparison_dict['score'].append(model_score)\n",
    "                \n",
    "prediction=score_classification(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of prediction output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba_0</th>\n",
       "      <th>proba_1</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.420175</td>\n",
       "      <td>0.579825</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.700513</td>\n",
       "      <td>0.299487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.951893</td>\n",
       "      <td>0.048107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.961263</td>\n",
       "      <td>0.038737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.988020</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.990970</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.991762</td>\n",
       "      <td>0.008238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.996645</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.996676</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.999016</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     proba_0   proba_1  actual  predicted\n",
       "0   0.420175  0.579825       1          1\n",
       "1   0.700513  0.299487       0          0\n",
       "2   0.951893  0.048107       0          0\n",
       "3   0.961263  0.038737       0          0\n",
       "4   0.988020  0.011980       0          0\n",
       "5   0.990970  0.009030       0          0\n",
       "6   0.991762  0.008238       0          0\n",
       "7   0.996645  0.003355       0          0\n",
       "8   0.996676  0.003324       0          0\n",
       "9   0.999016  0.000984       0          0\n",
       "10  0.999451  0.000549       0          0\n",
       "11  0.999901  0.000099       0          0\n",
       "12  0.999931  0.000069       0          0\n",
       "13  0.999935  0.000065       0          0\n",
       "14  0.999979  0.000021       0          0\n",
       "15  0.999982  0.000018       0          0\n",
       "16  0.999986  0.000014       0          0\n",
       "17  0.999996  0.000004       0          0\n",
       "18  0.999997  0.000003       0          0\n",
       "19  0.999999  0.000001       0          0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "logistic_regression          0.571429\n",
       "neural_network_classifier    0.571429\n",
       "random_forest_classifier     0.523810\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(comparison_dict).groupby('model')['score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neural_network_classifier</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model     score\n",
       "0        logistic_regression  0.571429\n",
       "1  neural_network_classifier  0.571429\n",
       "2   random_forest_classifier  0.476190"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models=pd.DataFrame(pd.DataFrame(comparison_dict).groupby('model')['score'].max())\n",
    "best_models.reset_index(inplace=True)\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "best_models.plot.bar(x=\"model\", y=\"score\", rot=70, title=\"Model scores\");\n",
    "\n",
    "plot.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_models=pd.DataFrame(comparison_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Model_info=pd.merge(best_models,All_models,how='left',left_on=['model','score'],right_on=['model','score'])\n",
    "Best_Model_info.drop_duplicates(keep=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>(l1, liblinear, 1.438449888287663)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>(l1, liblinear, 2.3357214690901213)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>(l1, liblinear, 3.792690190732246)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>(l1, liblinear, 6.158482110660261)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>(l1, liblinear, 10.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>(l2, liblinear, 2.3357214690901213)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>(l2, liblinear, 3.792690190732246)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>(l2, liblinear, 6.158482110660261)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>(l2, liblinear, 10.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neural_network_classifier</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>((75, 25, 50, 10), identity, lbfgs, 0.01623776...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, 0.8, 9.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, 0.8, 11.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, 0.8, 13.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, 0.8, 19.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, 0.8, 27.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, 0.8, 41.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, 0.8, 45.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, auto, 17.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, auto, 21.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, auto, 25.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, auto, 37.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, auto, 45.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, auto, 51.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, None, 21.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, None, 31.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(gini, None, 43.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(entropy, 0.8, 23.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(entropy, 0.8, 33.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(entropy, 0.8, 37.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(entropy, auto, 9.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(entropy, auto, 25.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(entropy, auto, 43.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(entropy, auto, 47.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>random_forest_classifier</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(entropy, None, 17.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model     score  \\\n",
       "0         logistic_regression  0.571429   \n",
       "1         logistic_regression  0.571429   \n",
       "2         logistic_regression  0.571429   \n",
       "3         logistic_regression  0.571429   \n",
       "4         logistic_regression  0.571429   \n",
       "5         logistic_regression  0.571429   \n",
       "6         logistic_regression  0.571429   \n",
       "7         logistic_regression  0.571429   \n",
       "8         logistic_regression  0.571429   \n",
       "9   neural_network_classifier  0.571429   \n",
       "10   random_forest_classifier  0.476190   \n",
       "11   random_forest_classifier  0.476190   \n",
       "12   random_forest_classifier  0.476190   \n",
       "13   random_forest_classifier  0.476190   \n",
       "14   random_forest_classifier  0.476190   \n",
       "15   random_forest_classifier  0.476190   \n",
       "16   random_forest_classifier  0.476190   \n",
       "17   random_forest_classifier  0.476190   \n",
       "18   random_forest_classifier  0.476190   \n",
       "19   random_forest_classifier  0.476190   \n",
       "20   random_forest_classifier  0.476190   \n",
       "21   random_forest_classifier  0.476190   \n",
       "22   random_forest_classifier  0.476190   \n",
       "23   random_forest_classifier  0.476190   \n",
       "24   random_forest_classifier  0.476190   \n",
       "25   random_forest_classifier  0.476190   \n",
       "26   random_forest_classifier  0.476190   \n",
       "27   random_forest_classifier  0.476190   \n",
       "28   random_forest_classifier  0.476190   \n",
       "29   random_forest_classifier  0.476190   \n",
       "30   random_forest_classifier  0.476190   \n",
       "31   random_forest_classifier  0.476190   \n",
       "32   random_forest_classifier  0.476190   \n",
       "33   random_forest_classifier  0.476190   \n",
       "\n",
       "                                               params  \n",
       "0                  (l1, liblinear, 1.438449888287663)  \n",
       "1                 (l1, liblinear, 2.3357214690901213)  \n",
       "2                  (l1, liblinear, 3.792690190732246)  \n",
       "3                  (l1, liblinear, 6.158482110660261)  \n",
       "4                               (l1, liblinear, 10.0)  \n",
       "5                 (l2, liblinear, 2.3357214690901213)  \n",
       "6                  (l2, liblinear, 3.792690190732246)  \n",
       "7                  (l2, liblinear, 6.158482110660261)  \n",
       "8                               (l2, liblinear, 10.0)  \n",
       "9   ((75, 25, 50, 10), identity, lbfgs, 0.01623776...  \n",
       "10                                   (gini, 0.8, 9.0)  \n",
       "11                                  (gini, 0.8, 11.0)  \n",
       "12                                  (gini, 0.8, 13.0)  \n",
       "13                                  (gini, 0.8, 19.0)  \n",
       "14                                  (gini, 0.8, 27.0)  \n",
       "15                                  (gini, 0.8, 41.0)  \n",
       "16                                  (gini, 0.8, 45.0)  \n",
       "17                                 (gini, auto, 17.0)  \n",
       "18                                 (gini, auto, 21.0)  \n",
       "19                                 (gini, auto, 25.0)  \n",
       "20                                 (gini, auto, 37.0)  \n",
       "21                                 (gini, auto, 45.0)  \n",
       "22                                 (gini, auto, 51.0)  \n",
       "23                                 (gini, None, 21.0)  \n",
       "24                                 (gini, None, 31.0)  \n",
       "25                                 (gini, None, 43.0)  \n",
       "26                               (entropy, 0.8, 23.0)  \n",
       "27                               (entropy, 0.8, 33.0)  \n",
       "28                               (entropy, 0.8, 37.0)  \n",
       "29                               (entropy, auto, 9.0)  \n",
       "30                              (entropy, auto, 25.0)  \n",
       "31                              (entropy, auto, 43.0)  \n",
       "32                              (entropy, auto, 47.0)  \n",
       "33                              (entropy, None, 17.0)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Please note that the NN classifier takes around 4+ hours to run and therefore only the best hyperparameters were left for it but the original function can be found below (with the entire grid search.)\n",
    "\n",
    "Best_Model_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
